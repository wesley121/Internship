{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ce83fb0",
   "metadata": {},
   "source": [
    "###  1. Finding Wikipedia header tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b6c3d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2c2ff4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_link  = \"https://www.wikipedia.org/\" \n",
    "\n",
    "wiki_site_data = requests.get(wiki_link)\n",
    "\n",
    "soup1 = BeautifulSoup(wiki_site_data.content , \"html.parser\")\n",
    "\n",
    "header = soup1.find_all('header')\n",
    "\n",
    "# Seems like there are no header tags on the wikipedia website. \n",
    "# The same has been found using the search option on the Inspect page section. \n",
    "# lets try if there are any 'head's¶\n",
    "\n",
    "head = soup1.find(\"head\")\n",
    "#soup1.find_all(\"head\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60c415e",
   "metadata": {},
   "source": [
    "### 2. Function to get top 100 rated movies from IMDB when provided with the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb28fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "imdb_top_link = \"https://www.imdb.com/chart/top/?ref_=nv_mv_250\"\n",
    "\n",
    "imdb_top_indian_link = \"https://www.imdb.com/india/top-rated-indian-movies/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=461131e5-5af0-4e50-bee2-223fad1e00ca&pf_rd_r=YGMQ7QBSZRY8RE39C7KD&pf_rd_s=center-1&pf_rd_t=60601&pf_rd_i=india.toprated&ref_=fea_india_ss_toprated_india_tr_india250_sm\"\n",
    "\n",
    "\n",
    "def find_top_100(link):\n",
    "\n",
    "    \n",
    "    imdb_site_data = requests.get(link)\n",
    "\n",
    "    soup_imdb = BeautifulSoup(imdb_site_data.content , \"html.parser\")\n",
    "\n",
    "    scrapedtitles = soup_imdb.find_all('td' , class_ = \"titleColumn\" )\n",
    "\n",
    "    titles = []\n",
    "\n",
    "    for title in scrapedtitles:\n",
    "        title = title.get_text().strip().replace('\\n' , \"\")[8:].strip()\n",
    "        titles.append(title)\n",
    "\n",
    "    titles\n",
    "\n",
    "    scrapedratings = soup_imdb.find_all('td' , class_ = \"ratingColumn imdbRating\" )\n",
    "\n",
    "    ratings = []\n",
    "\n",
    "    for rating in scrapedratings:\n",
    "        rating = rating.get_text().strip()\n",
    "        ratings.append(rating)\n",
    "\n",
    "    years = []\n",
    "\n",
    "    for title in titles:\n",
    "        year = title[-5:-1]\n",
    "        years.append(year)\n",
    "\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "    data['Title'] = titles\n",
    "    data['Year'] = years\n",
    "    data['Rating'] = ratings\n",
    "\n",
    "\n",
    "    top_imdb_100_movies = data[0:101]\n",
    "\n",
    "\n",
    "\n",
    "    return top_imdb_100_movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04fc382c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption(1994)</td>\n",
       "      <td>1994</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather(1972)</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight(2008)</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather Part II(1974)</td>\n",
       "      <td>1974</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men(1957)</td>\n",
       "      <td>1957</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>M - Eine Stadt sucht einen Mörder(1931)</td>\n",
       "      <td>1931</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>North by Northwest(1959)</td>\n",
       "      <td>1959</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Vertigo(1958)</td>\n",
       "      <td>1958</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Idi i smotri(1985)</td>\n",
       "      <td>1985</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Le fabuleux destin d'Amélie Poulain(2001)</td>\n",
       "      <td>2001</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Title  Year Rating\n",
       "0               The Shawshank Redemption(1994)  1994    9.2\n",
       "1                          The Godfather(1972)  1972    9.2\n",
       "2                        The Dark Knight(2008)  2008    9.0\n",
       "3                  The Godfather Part II(1974)  1974    9.0\n",
       "4                           12 Angry Men(1957)  1957    8.9\n",
       "..                                         ...   ...    ...\n",
       "96     M - Eine Stadt sucht einen Mörder(1931)  1931    8.3\n",
       "97                    North by Northwest(1959)  1959    8.3\n",
       "98                               Vertigo(1958)  1958    8.2\n",
       "99                          Idi i smotri(1985)  1985    8.2\n",
       "100  Le fabuleux destin d'Amélie Poulain(2001)  2001    8.2\n",
       "\n",
       "[101 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_100(imdb_top_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545da753",
   "metadata": {},
   "source": [
    "### 3. Function to get top 100 rated INDIAN movies from IMDB when provided with the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb799511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rocketry: The Nambi Effect(2022)</td>\n",
       "      <td>2022</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anbe Sivam(2003)</td>\n",
       "      <td>2003</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Golmaal(1979)</td>\n",
       "      <td>1979</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jai Bhim(2021)</td>\n",
       "      <td>2021</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nayakan(1987)</td>\n",
       "      <td>1987</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Baasha(1995)</td>\n",
       "      <td>1995</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Baahubali 2: The Conclusion(2017)</td>\n",
       "      <td>2017</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Masaan(2015)</td>\n",
       "      <td>2015</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Kahaani(2012)</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Dil Chahta Hai(2001)</td>\n",
       "      <td>2001</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title  Year Rating\n",
       "0     Rocketry: The Nambi Effect(2022)  2022    8.5\n",
       "1                     Anbe Sivam(2003)  2003    8.4\n",
       "2                        Golmaal(1979)  1979    8.4\n",
       "3                       Jai Bhim(2021)  2021    8.4\n",
       "4                        Nayakan(1987)  1987    8.4\n",
       "..                                 ...   ...    ...\n",
       "96                        Baasha(1995)  1995    8.0\n",
       "97   Baahubali 2: The Conclusion(2017)  2017    8.0\n",
       "98                        Masaan(2015)  2015    8.0\n",
       "99                       Kahaani(2012)  2012    8.0\n",
       "100               Dil Chahta Hai(2001)  2001    8.0\n",
       "\n",
       "[101 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_100(imdb_top_indian_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54c69c9",
   "metadata": {},
   "source": [
    "### 4. Program to display list of respected former presidents of India(i.e. Name , Term of office)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "252563a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_presidents_link = \"https://presidentofindia.nic.in/former-presidents.htm\"\n",
    "\n",
    "def india_presidents(link):\n",
    "    \n",
    "\n",
    "    site_content = requests.get(link)\n",
    "\n",
    "    india_presidents_soup = BeautifulSoup(site_content.content , \"html.parser\")\n",
    "\n",
    "    scraped_names = india_presidents_soup.find_all(\"h3\")\n",
    "\n",
    "    names = []\n",
    "    for name in scraped_names:\n",
    "        name = name.get_text()\n",
    "        names.append(name)\n",
    "\n",
    "    scraped_p = india_presidents_soup.find_all(\"p\" )\n",
    "\n",
    "    spans = []\n",
    "    for p in scraped_p:\n",
    "        if p.find('span'):\n",
    "            spans.append(p.text)\n",
    "\n",
    "    terms = []\n",
    "\n",
    "    for span in spans[:-1]:\n",
    "        span = span[16:]\n",
    "        terms.append(span)\n",
    "\n",
    "    presidents_of_india = pd.DataFrame()\n",
    "\n",
    "    presidents_of_india[\"Name\"] = names\n",
    "    presidents_of_india['Term'] = terms\n",
    "    \n",
    "    return presidents_of_india\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eed0cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind (birth - 1945)</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee (1935-2020)</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil (birth - 1934)</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam (1931-2015)</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan (1920 - 2005)</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma (1918-1999)</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman (1910-2009)</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh (1916-1994)</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy (1913-1996)</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed (1905-1977)</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri (1894-1980)</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain (1897-1969)</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan (1888-1975)</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad (1884-1963)</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Name  \\\n",
       "0           Shri Ram Nath Kovind (birth - 1945)   \n",
       "1             Shri Pranab Mukherjee (1935-2020)   \n",
       "2   Smt Pratibha Devisingh Patil (birth - 1934)   \n",
       "3            DR. A.P.J. Abdul Kalam (1931-2015)   \n",
       "4            Shri K. R. Narayanan (1920 - 2005)   \n",
       "5           Dr Shankar Dayal Sharma (1918-1999)   \n",
       "6               Shri R Venkataraman (1910-2009)   \n",
       "7                  Giani Zail Singh (1916-1994)   \n",
       "8         Shri Neelam Sanjiva Reddy (1913-1996)   \n",
       "9          Dr. Fakhruddin Ali Ahmed (1905-1977)   \n",
       "10     Shri Varahagiri Venkata Giri (1894-1980)   \n",
       "11                 Dr. Zakir Husain (1897-1969)   \n",
       "12     Dr. Sarvepalli Radhakrishnan (1888-1975)   \n",
       "13             Dr. Rajendra Prasad (1884-1963)    \n",
       "\n",
       "                                                 Term  \n",
       "0                     25 July, 2017 to 25 July, 2022   \n",
       "1                     25 July, 2012 to 25 July, 2017   \n",
       "2                     25 July, 2007 to 25 July, 2012   \n",
       "3                     25 July, 2002 to 25 July, 2007   \n",
       "4                     25 July, 1997 to 25 July, 2002   \n",
       "5                     25 July, 1992 to 25 July, 1997   \n",
       "6                     25 July, 1987 to 25 July, 1992   \n",
       "7                     25 July, 1982 to 25 July, 1987   \n",
       "8                     25 July, 1977 to 25 July, 1982   \n",
       "9                24 August, 1974 to 11 February, 1977  \n",
       "10  3 May, 1969 to 20 July, 1969 and 24 August, 19...  \n",
       "11                        13 May, 1967 to 3 May, 1969  \n",
       "12                       13 May, 1962 to 13 May, 1967  \n",
       "13                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "india_presidents(indian_presidents_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b640a3",
   "metadata": {},
   "source": [
    "## Programs to scrape cricket rankings - MEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69302024",
   "metadata": {},
   "source": [
    "### 5a - Top ODI teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b1c3075",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_men_link = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "batting_men_link = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "bowling_men_link = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "\n",
    "team_women_link = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "batting_women_link = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "bowling_women_link = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling\"\n",
    "\n",
    "\n",
    "def top_10_odi_teams_men(link) : \n",
    "    site_data_team_men = requests.get(link)\n",
    "\n",
    "    soup_team_men = BeautifulSoup(site_data_team_men.content, \"html.parser\")\n",
    "\n",
    "    scraped_teams_men = soup_team_men.find_all(\"span\" , class_ = \"u-hide-phablet\")\n",
    "\n",
    "    teams_men = []\n",
    "    for team in scraped_teams_men:\n",
    "        team = team.get_text()\n",
    "        teams_men.append(team)\n",
    "\n",
    "    scraped_team_men_matches = soup_team_men.find_all(\"td\" , class_ = \"table-body__cell u-center-text\" )\n",
    "\n",
    "    matches_men =  []\n",
    "    matches_men.append('15')\n",
    "\n",
    "    for match in scraped_team_men_matches:\n",
    "        if scraped_team_men_matches.index(match) % 2  == 0 :\n",
    "            match = match.get_text()\n",
    "            matches_men.append(match)\n",
    "\n",
    "    points_men =  []\n",
    "    points_men.append('1913')\n",
    "\n",
    "    for match in scraped_team_men_matches:\n",
    "        if scraped_team_men_matches.index(match) % 2  == 1 :\n",
    "            match = match.get_text()\n",
    "            points_men.append(match)\n",
    "\n",
    "    ratings_men =  []\n",
    "    ratings_men.append('128')\n",
    "\n",
    "    scraped_team_men_ratings = soup_team_men.find_all(\"td\" , class_ = \"table-body__cell u-text-right rating\" )\n",
    "\n",
    "    for rating in scraped_team_men_ratings:\n",
    "        rating = rating.get_text()\n",
    "        ratings_men.append(rating)\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    data[\"Team\"] = teams_men\n",
    "    data[\"Matches\"] = matches_men\n",
    "    data['Points'] = points_men\n",
    "    data[\"Rating\"] = ratings_men\n",
    "\n",
    "    top_10_odi_teams_men = data[0:11]\n",
    "\n",
    "    return (top_10_odi_teams_men)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef916cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>15</td>\n",
       "      <td>1913</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>27</td>\n",
       "      <td>3,226</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>28</td>\n",
       "      <td>3,085</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>19</td>\n",
       "      <td>2,005</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>23</td>\n",
       "      <td>2,325</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>21</td>\n",
       "      <td>2,111</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>27</td>\n",
       "      <td>2,639</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>29</td>\n",
       "      <td>2,658</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>38</td>\n",
       "      <td>2,621</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>18</td>\n",
       "      <td>1,238</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>23</td>\n",
       "      <td>1,214</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Team Matches Points Rating\n",
       "0    New Zealand      15   1913    128\n",
       "1        England      27  3,226    119\n",
       "2          India      28  3,085    110\n",
       "3       Pakistan      19  2,005    106\n",
       "4      Australia      23  2,325    101\n",
       "5   South Africa      21  2,111    101\n",
       "6     Bangladesh      27  2,639     98\n",
       "7      Sri Lanka      29  2,658     92\n",
       "8    West Indies      38  2,621     69\n",
       "9    Afghanistan      18  1,238     69\n",
       "10       Ireland      23  1,214     53"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_odi_teams_men(team_men_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c420669",
   "metadata": {},
   "source": [
    "### 6a - Top ODI teams - Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "769a644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>15</td>\n",
       "      <td>1913</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>33</td>\n",
       "      <td>4,046</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>35</td>\n",
       "      <td>4,157</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>32</td>\n",
       "      <td>3,219</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>31</td>\n",
       "      <td>3,019</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>30</td>\n",
       "      <td>2,768</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>12</td>\n",
       "      <td>930</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>30</td>\n",
       "      <td>1,962</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>11</td>\n",
       "      <td>495</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>8</td>\n",
       "      <td>351</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Team Matches Points Rating\n",
       "0      Australia      15   1913    128\n",
       "1        England      33  4,046    123\n",
       "2   South Africa      35  4,157    119\n",
       "3          India      32  3,219    101\n",
       "4    New Zealand      31  3,019     97\n",
       "5    West Indies      30  2,768     92\n",
       "6     Bangladesh      12    930     78\n",
       "7       Pakistan      30  1,962     65\n",
       "8      Sri Lanka      11    495     45\n",
       "9        Ireland       8    351     44\n",
       "10      Zimbabwe       8      0      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_odi_teams_men(team_women_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e504626a",
   "metadata": {},
   "source": [
    "### 5b - Top ODI batsmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c88a944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_odi_batsmen(link):\n",
    "\n",
    "    site_data_5b = requests.get(link)\n",
    "\n",
    "    soup_5b = BeautifulSoup(site_data_5b.content ,\"html.parser\" )\n",
    "\n",
    "    players = []\n",
    "    teams = []\n",
    "    ratings = []\n",
    "\n",
    "    top_player = soup_5b.find(\"div\" , class_ = \"rankings-block__banner--name-large\")\n",
    "    players.append(top_player.get_text())\n",
    "\n",
    "    top_team = soup_5b.find(\"div\" , class_ = \"rankings-block__banner--nationality\")\n",
    "    teams.append(top_team.get_text().strip())\n",
    "\n",
    "    top_rating = soup_5b.find(\"div\" , class_ = \"rankings-block__banner--rating\")\n",
    "    ratings.append(top_rating.get_text())\n",
    "\n",
    "    scraped_players_5b = soup_5b.find_all(\"td\" , class_ = \"table-body__cell rankings-table__name name\" )\n",
    "\n",
    "\n",
    "    for player in scraped_players_5b:\n",
    "        player = player.get_text().strip()\n",
    "        players.append(player)\n",
    "\n",
    "    scraped_teams_5b = soup_5b.find_all(\"span\" , class_ = \"table-body__logo-text\" )\n",
    "\n",
    "\n",
    "    for team in scraped_teams_5b:\n",
    "        team = team.get_text().strip()\n",
    "        teams.append(team)\n",
    "\n",
    "\n",
    "    scraped_ratings_5b = soup_5b.find_all(\"td\" , class_ = \"table-body__cell rating\" )\n",
    "\n",
    "\n",
    "    for rating in scraped_ratings_5b:\n",
    "        rating = rating.get_text().strip()\n",
    "        ratings.append(rating)\n",
    "\n",
    "    data_5b = pd.DataFrame()\n",
    "\n",
    "    data_5b[\"Player\"] = players\n",
    "    data_5b[\"team\"] = teams\n",
    "    data_5b[\"Rating\"] = ratings\n",
    "\n",
    "    top_odi_batsmen = data_5b[:10]\n",
    "    \n",
    "    return top_odi_batsmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4012230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Player team Rating\n",
       "0             Babar Azam  PAK    892\n",
       "1            Imam-ul-Haq  PAK    815\n",
       "2  Rassie van der Dussen   SA    789\n",
       "3        Quinton de Kock   SA    784\n",
       "4            Virat Kohli  IND    774\n",
       "5           Rohit Sharma  IND    770\n",
       "6            Ross Taylor   NZ    752\n",
       "7           David Warner  AUS    737\n",
       "8         Jonny Bairstow  ENG    732\n",
       "9            Aaron Finch  AUS    715"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_odi_batsmen(batting_men_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d01f3cb",
   "metadata": {},
   "source": [
    "### 6b - Top ODI female batters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e263be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Player team Rating\n",
       "0         Alyssa Healy  AUS    785\n",
       "1          Beth Mooney  AUS    749\n",
       "2       Natalie Sciver  ENG    747\n",
       "3      Laura Wolvaardt   SA    732\n",
       "4          Meg Lanning  AUS    710\n",
       "5       Rachael Haynes  AUS    701\n",
       "6    Amy Satterthwaite   NZ    681\n",
       "7       Tammy Beaumont  ENG    667\n",
       "8  Chamari Athapaththu   SL    655\n",
       "9      Smriti Mandhana  IND    649"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_odi_batsmen(batting_women_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea3f0ee",
   "metadata": {},
   "source": [
    "### 5c - Top ODI bowlers - men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ff92698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_odi_bowlers(link):\n",
    "\n",
    "    site_data_5c = requests.get(link)\n",
    "\n",
    "    soup_5c = BeautifulSoup(site_data_5c.content ,\"html.parser\" )\n",
    "\n",
    "    players_5c = []\n",
    "    teams_5c = []\n",
    "    ratings_5c = []\n",
    "\n",
    "    top_player_5c = soup_5c.find(\"div\" , class_ = \"rankings-block__banner--name-large\")\n",
    "    players_5c.append(top_player_5c.get_text())\n",
    "\n",
    "    top_team_5c = soup_5c.find(\"div\" , class_ = \"rankings-block__banner--nationality\")\n",
    "    teams_5c.append(top_team_5c.get_text().strip())\n",
    "\n",
    "    top_rating_5c = soup_5c.find(\"div\" , class_ = \"rankings-block__banner--rating\")\n",
    "    ratings_5c.append(top_rating_5c.get_text())\n",
    "\n",
    "    scraped_players_5c = soup_5c.find_all(\"td\" , class_ = \"table-body__cell rankings-table__name name\" )\n",
    "\n",
    "    for player in scraped_players_5c:\n",
    "        player = player.get_text().strip()\n",
    "        players_5c.append(player)\n",
    "\n",
    "        \n",
    "    scraped_teams_5c = soup_5c.find_all(\"td\" , class_ = \"table-body__cell nationality-logo rankings-table__team\" )\n",
    "\n",
    "    for team in scraped_teams_5c:\n",
    "        team = team.get_text().strip()\n",
    "        teams_5c.append(team)\n",
    "\n",
    "\n",
    "    scraped_ratings_5c = soup_5c.find_all(\"td\" , class_ = \"table-body__cell rating\" )\n",
    "\n",
    "    for rating in scraped_ratings_5c:\n",
    "        rating = rating.get_text().strip()\n",
    "        ratings_5c.append(rating)\n",
    "\n",
    "    data_5c = pd.DataFrame()\n",
    "\n",
    "    data_5c[\"Player\"] = players_5c\n",
    "    data_5c[\"team\"] = teams_5c\n",
    "    data_5c[\"Rating\"] = ratings_5c\n",
    "\n",
    "    top_odi_bowlers = data_5c[:10]\n",
    "    \n",
    "    return top_odi_bowlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16634ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mohammad Nabi</td>\n",
       "      <td>AFG</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player team Rating\n",
       "0       Trent Boult   NZ    704\n",
       "1    Jasprit Bumrah  IND    689\n",
       "2    Shaheen Afridi  PAK    681\n",
       "3    Josh Hazlewood  AUS    679\n",
       "4  Mujeeb Ur Rahman  AFG    676\n",
       "5      Mehedi Hasan  BAN    672\n",
       "6        Matt Henry   NZ    670\n",
       "7     Mohammad Nabi  AFG    657\n",
       "8       Rashid Khan  AFG    651\n",
       "9      Chris Woakes  ENG    640"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_odi_bowlers(bowling_men_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e9a646",
   "metadata": {},
   "source": [
    "### 6c - Top ODI bowlers - Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb00a5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Megan Schutt</td>\n",
       "      <td>AUS</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shabnim Ismail</td>\n",
       "      <td>SA</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ayabonga Khaka</td>\n",
       "      <td>SA</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rajeshwari Gayakwad</td>\n",
       "      <td>IND</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Player team Rating\n",
       "0    Sophie Ecclestone  ENG    761\n",
       "1        Jess Jonassen  AUS    725\n",
       "2         Megan Schutt  AUS    722\n",
       "3       Shabnim Ismail   SA    722\n",
       "4       Jhulan Goswami  IND    644\n",
       "5       Ayabonga Khaka   SA    634\n",
       "6  Rajeshwari Gayakwad  IND    613\n",
       "7      Hayley Matthews   WI    612\n",
       "8      Katherine Brunt  ENG    601\n",
       "9       Marizanne Kapp   SA    598"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_odi_bowlers(bowling_women_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff022a5",
   "metadata": {},
   "source": [
    "### 7. Scraping news headlines - CNBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "37d32585",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnbc_link = \"https://www.cnbc.com/world/?region=world\"\n",
    "\n",
    "def get_headlines(link):    \n",
    "    \n",
    "    cnbc_site_data = requests.get(link)\n",
    "\n",
    "    cnbc_soup = BeautifulSoup(cnbc_site_data.content , \"html.parser\")\n",
    "\n",
    "    scraped_headlines = cnbc_soup.find_all(\"div\" , class_ = \"RiverPlusCard-container\")\n",
    "    headlines = []\n",
    "\n",
    "    for headline in scraped_headlines:\n",
    "        headline = headline.get_text()\n",
    "        headlines.append(headline)\n",
    "\n",
    "    links = []\n",
    "\n",
    "    for headline in scraped_headlines:\n",
    "        headline = headline.find('a').get('href')\n",
    "        links.append(headline)\n",
    "\n",
    "    scraped_times = cnbc_soup.find_all(\"span\" , class_ = \"RiverByline-datePublished\")\n",
    "\n",
    "    times = []\n",
    "\n",
    "    scraped_headline_rows = cnbc_soup.find_all(\"div\" , class_ = \"RiverPlusCard-container\")\n",
    "\n",
    "    for row in scraped_headline_rows:\n",
    "        row = row.find(\"span\" , class_ = \"RiverByline-datePublished\")\n",
    "        if row == None:\n",
    "            times.append(\"Not available\")\n",
    "        else: times.append(row.get_text())\n",
    "\n",
    "    headline_data = pd.DataFrame()\n",
    "\n",
    "    headline_data['Headline'] = headlines\n",
    "    headline_data['Time posted'] = times\n",
    "    headline_data['Link'] = links\n",
    "\n",
    "    return(headline_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aeb3cfbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time posted</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Instagram boss Adam Mosseri to move to London ...</td>\n",
       "      <td>2 hours ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/02/instagram-boss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>British Airways suspends the sale of short-hau...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>https://www.cnbc.com/2022/08/02/british-airway...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is the U.S. in a recession? This strategist is...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>/pro/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chinese e-commerce giant Alibaba teams up with...</td>\n",
       "      <td>an hour ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/02/chinas-alibaba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S&amp;P 500 rises as as investors weigh China tens...</td>\n",
       "      <td>Moments Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/01/stock-futures-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fed's Daly says 'our work is far from done' in...</td>\n",
       "      <td>5 min ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/02/feds-daly-says...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Draghi's political downfall: How power implode...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>https://www.cnbc.com/2022/08/02/how-italy-drag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How to make a passive income so you can quit y...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>https://www.cnbc.com/2022/07/30/how-to-make-a-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chinese warplanes buzz line dividing Taiwan St...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>https://www.cnbc.com/2022/08/02/chinese-warpla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>August could be good for stocks, but another b...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>/pro/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>German chemicals firm warns of production chai...</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/02/covestro-warns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I spent 5 years interviewing 225 millionaires....</td>\n",
       "      <td>Not available</td>\n",
       "      <td>https://www.cnbc.com/2022/07/31/i-spent-5-year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Oil major BP boosts dividend as quarterly prof...</td>\n",
       "      <td>an hour ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/02/oil-major-bp-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pelosi to visit Taiwan, local media say, despi...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>https://www.cnbc.com/2022/08/01/us-house-speak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Biden says drone strike killed al-Qaeda leader...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>https://www.cnbc.com/2022/08/01/biden-set-to-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>China's economy could be dragged down by loss ...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>https://www.cnbc.com/2022/08/02/chinas-economy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Maersk sees global supply chain woes for longe...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>https://www.cnbc.com/2022/08/02/shipping-compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Has the market hit bottom? Here’s what Wall St...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>/pro/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline    Time posted  \\\n",
       "0   Instagram boss Adam Mosseri to move to London ...    2 hours ago   \n",
       "1   British Airways suspends the sale of short-hau...  Not available   \n",
       "2   Is the U.S. in a recession? This strategist is...  Not available   \n",
       "3   Chinese e-commerce giant Alibaba teams up with...    an hour ago   \n",
       "4   S&P 500 rises as as investors weigh China tens...    Moments Ago   \n",
       "5   Fed's Daly says 'our work is far from done' in...      5 min ago   \n",
       "6   Draghi's political downfall: How power implode...  Not available   \n",
       "7   How to make a passive income so you can quit y...  Not available   \n",
       "8   Chinese warplanes buzz line dividing Taiwan St...  Not available   \n",
       "9   August could be good for stocks, but another b...  Not available   \n",
       "10  German chemicals firm warns of production chai...    5 hours ago   \n",
       "11  I spent 5 years interviewing 225 millionaires....  Not available   \n",
       "12  Oil major BP boosts dividend as quarterly prof...    an hour ago   \n",
       "13  Pelosi to visit Taiwan, local media say, despi...  Not available   \n",
       "14  Biden says drone strike killed al-Qaeda leader...  Not available   \n",
       "15  China's economy could be dragged down by loss ...  Not available   \n",
       "16  Maersk sees global supply chain woes for longe...  Not available   \n",
       "17  Has the market hit bottom? Here’s what Wall St...  Not available   \n",
       "\n",
       "                                                 Link  \n",
       "0   https://www.cnbc.com/2022/08/02/instagram-boss...  \n",
       "1   https://www.cnbc.com/2022/08/02/british-airway...  \n",
       "2                                               /pro/  \n",
       "3   https://www.cnbc.com/2022/08/02/chinas-alibaba...  \n",
       "4   https://www.cnbc.com/2022/08/01/stock-futures-...  \n",
       "5   https://www.cnbc.com/2022/08/02/feds-daly-says...  \n",
       "6   https://www.cnbc.com/2022/08/02/how-italy-drag...  \n",
       "7   https://www.cnbc.com/2022/07/30/how-to-make-a-...  \n",
       "8   https://www.cnbc.com/2022/08/02/chinese-warpla...  \n",
       "9                                               /pro/  \n",
       "10  https://www.cnbc.com/2022/08/02/covestro-warns...  \n",
       "11  https://www.cnbc.com/2022/07/31/i-spent-5-year...  \n",
       "12  https://www.cnbc.com/2022/08/02/oil-major-bp-e...  \n",
       "13  https://www.cnbc.com/2022/08/01/us-house-speak...  \n",
       "14  https://www.cnbc.com/2022/08/01/biden-set-to-s...  \n",
       "15  https://www.cnbc.com/2022/08/02/chinas-economy...  \n",
       "16  https://www.cnbc.com/2022/08/02/shipping-compa...  \n",
       "17                                              /pro/  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_headlines(cnbc_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fa1cf4",
   "metadata": {},
   "source": [
    "### 8. Most downloaded articles on AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "81c0cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_link = \"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\"\n",
    "\n",
    "def AI_top_articles(link):\n",
    "    AI_site_data = requests.get(link)\n",
    "    AI_soup = BeautifulSoup(AI_site_data.content , \"html.parser\")\n",
    "\n",
    "    scraped_titles = AI_soup.find_all(\"h2\" , class_ = \"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\")\n",
    "\n",
    "    titles = []\n",
    "\n",
    "    for title in scraped_titles:\n",
    "        title = title.get_text()\n",
    "        titles.append(title)\n",
    "\n",
    "    scraped_authors = AI_soup.find_all(\"span\" , class_ = \"sc-1w3fpd7-0 pgLAT\")\n",
    "\n",
    "    authors = []\n",
    "\n",
    "    for author in scraped_authors:\n",
    "        author = author.get_text()\n",
    "        authors.append(author)\n",
    "\n",
    "\n",
    "    scraped_dates = AI_soup.find_all(\"span\" , class_ = \"sc-1thf9ly-2 bKddwo\")\n",
    "\n",
    "    dates = []\n",
    "\n",
    "    for date in scraped_dates:\n",
    "        date = date.get_text()\n",
    "        dates.append(date)\n",
    "\n",
    "    scraped_links = AI_soup.find_all(\"li\" , class_ = \"sc-9zxyh7-1 sc-9zxyh7-2 exAXfr jQmQZp\")\n",
    "\n",
    "    links = []\n",
    "\n",
    "    for link in scraped_links:\n",
    "        link = link.find('a').get(\"href\")\n",
    "        links.append(link)\n",
    "\n",
    "    AI_top_articles = pd.DataFrame()\n",
    "\n",
    "    AI_top_articles[\"Paper Title\"] = titles\n",
    "    AI_top_articles['Authors'] = authors\n",
    "    AI_top_articles[\"Publised Date\"] = dates\n",
    "    AI_top_articles[\"Paper URL\"] = links\n",
    "\n",
    "    return AI_top_articles\n",
    "\n",
    "\n",
    "                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e2d4baa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publised Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              Authors   Publised Date  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                            Paper URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_top_articles(AI_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57f4322",
   "metadata": {},
   "source": [
    "### 9. DineOut restaurant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "779ca060",
   "metadata": {},
   "outputs": [],
   "source": [
    "dineout_link = \"https://www.dineout.co.in/hyderabad-restaurants/welcome-back\"\n",
    "\n",
    "def dineout_restaurants(link):\n",
    "    dine_site_data = requests.get(link)\n",
    "    dine_soup = BeautifulSoup(dine_site_data.content , \"html.parser\")\n",
    "\n",
    "    scraped_names = dine_soup.find_all('div' , class_ = \"restnt-info cursor\")\n",
    "\n",
    "    names = []\n",
    "\n",
    "    for name in scraped_names:\n",
    "        name = name.find('a').get_text()\n",
    "        names.append(name)\n",
    "\n",
    "    scraped_cuisines = dine_soup.find_all(\"span\" , class_ = \"double-line-ellipsis\")\n",
    "\n",
    "    cuisines = []\n",
    "\n",
    "    for cuisine in scraped_cuisines:\n",
    "        cuisine = cuisine.find_all('a')\n",
    "        text = \"\"\n",
    "        for a in cuisine:\n",
    "            text = text + ',' + ' ' +  a.get_text()\n",
    "\n",
    "\n",
    "        cuisines.append(text[2:])\n",
    "\n",
    "\n",
    "    scraped_locations = dine_soup.find_all(\"div\" , class_ = \"restnt-loc ellipsis\")\n",
    "\n",
    "    locations = []\n",
    "\n",
    "    for location in scraped_locations:\n",
    "        location = location.find_all('a')\n",
    "        text = \"\"\n",
    "        for a in location:\n",
    "            text = text + ',' + ' ' +  a.get_text().strip(',')\n",
    "\n",
    "\n",
    "        locations.append(text[2:])\n",
    "\n",
    "    scraped_ratings = dine_soup.find_all(\"div\" , class_ = \"restnt-rating rating-4\")\n",
    "\n",
    "    ratings = []\n",
    "\n",
    "    for rating in scraped_ratings:\n",
    "        rating = rating.get_text()\n",
    "        ratings.append(rating)\n",
    "\n",
    "\n",
    "    scraped_images = dine_soup.find_all(\"img\" , class_ = \"no-img\")\n",
    "\n",
    "    images = []\n",
    "\n",
    "    for image in scraped_images:\n",
    "        image = image.get(\"data-src\")\n",
    "        images.append(image)\n",
    "\n",
    "    images\n",
    "\n",
    "    dineout_data = pd.DataFrame()\n",
    "\n",
    "    dineout_data[\"Restaurant Name\"] = names\n",
    "    dineout_data[\"Cuisine\"] = cuisines\n",
    "    dineout_data[\"Location\"] = locations\n",
    "    dineout_data[\"Ratings\"] = ratings\n",
    "    dineout_data[\"Image URL\"] = images\n",
    "\n",
    "\n",
    "    return dineout_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4e3eb2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Krishnapatnam</td>\n",
       "      <td>Andhra, South Indian, Mughlai</td>\n",
       "      <td>Shreshta Aura, Jubilee Hills, Central West Hyd...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ohri's Jiva</td>\n",
       "      <td>North Indian, Chinese, Rajasthani, South Indian</td>\n",
       "      <td>White House, Begumpet, Secunderabad</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Headquarters</td>\n",
       "      <td>Chinese, Continental, North Indian</td>\n",
       "      <td>Somajiguda, Central East Hyderabad</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABs - Absolute Barbecues</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Banjara Hills, Central East Hyderabad</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amogham - The Lake View Restaurant</td>\n",
       "      <td>Chinese, North Indian, Continental, Mughlai</td>\n",
       "      <td>Khairatabad, Central Hyderabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10 Downing Street</td>\n",
       "      <td>Finger Food, Chinese, Continental, North Indian</td>\n",
       "      <td>Lifestyle Building, Begumpet, Secunderabad</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Barbeque Nation</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>ANR Center, Banjara Hills, Central East Hyderabad</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ABs - Absolute Barbecues</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>SD Road, Secunderabad</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Exotica</td>\n",
       "      <td>Mughlai, North Indian, Chinese</td>\n",
       "      <td>12th Square Building, Banjara Hills, Central E...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A'La Liberty</td>\n",
       "      <td>North Indian, Chinese, Mexican</td>\n",
       "      <td>Leela Gopal Towers, Banjara Hills, Central Eas...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>By The Bay - Bar Exchange</td>\n",
       "      <td>North Indian, Continental, Chinese</td>\n",
       "      <td>Khairatabad, Central Hyderabad</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bikanervala</td>\n",
       "      <td>North Indian, Street Food, Fast Food</td>\n",
       "      <td>Banjara Hills, Central East Hyderabad</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Parampara - Flavours of india</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>ANR Center, Banjara Hills, Central East Hyderabad</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Verandah</td>\n",
       "      <td>Chinese, North Indian, Continental, Italian</td>\n",
       "      <td>The Park, Somajiguda, Central East Hyderabad</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>Pizza, Fast Food</td>\n",
       "      <td>The Grand Building, Somajiguda, Central East H...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hard Rock Cafe</td>\n",
       "      <td>Continental, American, Fast Food</td>\n",
       "      <td>GVK One Mall, Banjara Hills, Central East Hyde...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Seven Spices</td>\n",
       "      <td>Andhra, Biryani</td>\n",
       "      <td>Somajiguda, Central East Hyderabad</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Krishnapatnam</td>\n",
       "      <td>South Indian, Andhra, Mughlai</td>\n",
       "      <td>Forum Sujana Mall, Kukatpally, West Hyderabad</td>\n",
       "      <td>3.6</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Eagles Pizza</td>\n",
       "      <td>Pizza, Fast Food</td>\n",
       "      <td>Ohud Building, Somajiguda, Central East Hyderabad</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cream Stone</td>\n",
       "      <td>Desserts, Beverages</td>\n",
       "      <td>The Platinum Hotel, Himayath Nagar, Central Hy...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Hashi Izakaya - Asian Bar &amp; Kitchen</td>\n",
       "      <td>Chinese, Thai, Japanese</td>\n",
       "      <td>Country Club Complex, Begumpet, Secunderabad</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Restaurant Name  \\\n",
       "0                         Krishnapatnam   \n",
       "1                           Ohri's Jiva   \n",
       "2                          Headquarters   \n",
       "3              ABs - Absolute Barbecues   \n",
       "4    Amogham - The Lake View Restaurant   \n",
       "5                     10 Downing Street   \n",
       "6                       Barbeque Nation   \n",
       "7              ABs - Absolute Barbecues   \n",
       "8                               Exotica   \n",
       "9                          A'La Liberty   \n",
       "10            By The Bay - Bar Exchange   \n",
       "11                          Bikanervala   \n",
       "12        Parampara - Flavours of india   \n",
       "13                             Verandah   \n",
       "14                            Pizza Hut   \n",
       "15                       Hard Rock Cafe   \n",
       "16                         Seven Spices   \n",
       "17                        Krishnapatnam   \n",
       "18                         Eagles Pizza   \n",
       "19                          Cream Stone   \n",
       "20  Hashi Izakaya - Asian Bar & Kitchen   \n",
       "\n",
       "                                            Cuisine  \\\n",
       "0                     Andhra, South Indian, Mughlai   \n",
       "1   North Indian, Chinese, Rajasthani, South Indian   \n",
       "2                Chinese, Continental, North Indian   \n",
       "3                                      North Indian   \n",
       "4       Chinese, North Indian, Continental, Mughlai   \n",
       "5   Finger Food, Chinese, Continental, North Indian   \n",
       "6                             North Indian, Chinese   \n",
       "7                                      North Indian   \n",
       "8                    Mughlai, North Indian, Chinese   \n",
       "9                    North Indian, Chinese, Mexican   \n",
       "10               North Indian, Continental, Chinese   \n",
       "11             North Indian, Street Food, Fast Food   \n",
       "12                            Chinese, North Indian   \n",
       "13      Chinese, North Indian, Continental, Italian   \n",
       "14                                 Pizza, Fast Food   \n",
       "15                 Continental, American, Fast Food   \n",
       "16                                  Andhra, Biryani   \n",
       "17                    South Indian, Andhra, Mughlai   \n",
       "18                                 Pizza, Fast Food   \n",
       "19                              Desserts, Beverages   \n",
       "20                          Chinese, Thai, Japanese   \n",
       "\n",
       "                                             Location Ratings  \\\n",
       "0   Shreshta Aura, Jubilee Hills, Central West Hyd...     3.9   \n",
       "1                 White House, Begumpet, Secunderabad       4   \n",
       "2                  Somajiguda, Central East Hyderabad     4.1   \n",
       "3               Banjara Hills, Central East Hyderabad     4.3   \n",
       "4                      Khairatabad, Central Hyderabad     3.8   \n",
       "5          Lifestyle Building, Begumpet, Secunderabad     4.3   \n",
       "6   ANR Center, Banjara Hills, Central East Hyderabad     4.2   \n",
       "7                               SD Road, Secunderabad     4.1   \n",
       "8   12th Square Building, Banjara Hills, Central E...     4.4   \n",
       "9   Leela Gopal Towers, Banjara Hills, Central Eas...     4.1   \n",
       "10                     Khairatabad, Central Hyderabad     4.1   \n",
       "11              Banjara Hills, Central East Hyderabad     4.2   \n",
       "12  ANR Center, Banjara Hills, Central East Hyderabad       4   \n",
       "13       The Park, Somajiguda, Central East Hyderabad     3.9   \n",
       "14  The Grand Building, Somajiguda, Central East H...     4.4   \n",
       "15  GVK One Mall, Banjara Hills, Central East Hyde...     4.3   \n",
       "16                 Somajiguda, Central East Hyderabad     4.2   \n",
       "17      Forum Sujana Mall, Kukatpally, West Hyderabad     3.6   \n",
       "18  Ohud Building, Somajiguda, Central East Hyderabad     3.9   \n",
       "19  The Platinum Hotel, Himayath Nagar, Central Hy...     4.3   \n",
       "20       Country Club Complex, Begumpet, Secunderabad     4.2   \n",
       "\n",
       "                                            Image URL  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "13  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "14  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "15  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "16  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "17  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "18  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "19  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "20  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dineout_restaurants(dineout_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e6b594",
   "metadata": {},
   "source": [
    "### 10. Google's publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6fcc7837",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_link = \"https://scholar.google.com/citations?view_op=top_venues&hl=en\"\n",
    "\n",
    "def google_publications(link):\n",
    "    google_site_data = requests.get(link)\n",
    "    google_soup = BeautifulSoup(google_site_data.content , \"html.parser\")\n",
    "\n",
    "    scraped_ranks = google_soup.find_all(\"td\" , class_ = \"gsc_mvt_p\")\n",
    "    scraped_publication = google_soup.find_all(\"td\" , class_ = \"gsc_mvt_t\")\n",
    "    scraped_index = google_soup.find_all(\"a\" , class_ = \"gs_ibl gsc_mp_anchor\")\n",
    "    scraped_median = google_soup.find_all(\"span\" , class_ = \"gs_ibl gsc_mp_anchor\")\n",
    "\n",
    "    publications = []\n",
    "    ranks = []\n",
    "    indexs = []\n",
    "    medians = []\n",
    "\n",
    "    for rank in scraped_ranks:\n",
    "        rank = rank.get_text()\n",
    "        ranks.append(rank)\n",
    "\n",
    "    for publication in scraped_publication:\n",
    "        publication = publication.get_text()\n",
    "        publications.append(publication)\n",
    "\n",
    "    for index in scraped_index:\n",
    "        index = index.get_text()\n",
    "        indexs.append(index)\n",
    "\n",
    "    for median in scraped_median:\n",
    "        median = median.get_text()\n",
    "        medians.append(median)\n",
    "\n",
    "\n",
    "    google_data = pd.DataFrame()\n",
    "\n",
    "    google_data[\"Rank\"] = ranks\n",
    "    google_data[\"Publication\"] = publications\n",
    "    google_data[\"H5-index\"] = indexs\n",
    "    google_data[\"H5-median\"] = medians\n",
    "\n",
    "\n",
    "    return google_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "04c5176e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication</th>\n",
       "      <th>H5-index</th>\n",
       "      <th>H5-median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>432</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>401</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>389</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>354</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>145</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>Sensors</td>\n",
       "      <td>145</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>144</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>144</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                        Publication H5-index H5-median\n",
       "0     1.                                             Nature      444       667\n",
       "1     2.                The New England Journal of Medicine      432       780\n",
       "2     3.                                            Science      401       614\n",
       "3     4.  IEEE/CVF Conference on Computer Vision and Pat...      389       627\n",
       "4     5.                                         The Lancet      354       635\n",
       "..   ...                                                ...      ...       ...\n",
       "95   96.                       Journal of Business Research      145       233\n",
       "96   97.                                   Molecular Cancer      145       209\n",
       "97   98.                                            Sensors      145       201\n",
       "98   99.                              Nature Climate Change      144       228\n",
       "99  100.                    IEEE Internet of Things Journal      144       212\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_publications(google_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0567845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
